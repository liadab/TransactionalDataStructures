#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
%%AGT class -- Feldman -- TAU -- Spring 2018 %%


    \textwidth=6in
    \oddsidemargin=0.25in
    \evensidemargin=0.25in
    \topmargin=-0.1in
    \footskip=0.8in
    \parindent=0.0cm
    \parskip=0.3cm
    \textheight=8.00in


    \sloppy

    \DeclareMathOperator*{\argmax}{argmax}
    \DeclareMathOperator*{\argmin}{argmin}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding utf8
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
oddsidemargin}{.25in}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
evensidemargin}{.25in}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
textwidth}{6in}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
topmargin}{-0.4in}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
textheight}{8.5in}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\handout}[4]{ \global\long\global\long\newcommand{\thepage}{#1-\arabic{page}}\noindent\begin{center} \framebox[][]{ \vbox{ \hbox to 6.35in { {\bf Advanced Topics in Multi-Core Architecture and Software Systems} \hfill#1 } \vspace{4mm} \hbox to 5.78in { {\Large\hfill#4 \hfill} } \vspace{2mm} \hbox to 6.35in { {\it #2 \hfill#3} } } } \end{center} \vspace*{4mm} }
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\finalProjTitle}[4]{\handout{#1}{Lecturer: #2}{Names: #3}{#4}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{theorem}{
\end_layout

\end_inset

Theorem
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{corollary}[theorem]{
\end_layout

\end_inset

Corollary
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{lemma}[theorem]{
\end_layout

\end_inset

Lemma
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{observation}[theorem]{
\end_layout

\end_inset

Observation
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{proposition}[theorem]{
\end_layout

\end_inset

Proposition
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{definition}[theorem]{
\end_layout

\end_inset

Definition
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{claim}[theorem]{
\end_layout

\end_inset

Claim
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{fact}[theorem]{
\end_layout

\end_inset

Fact
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{assumption}[theorem]{
\end_layout

\end_inset

Assumption
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{example}{
\end_layout

\end_inset

Example
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\qed}{\rule{7pt}{7pt}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{proof}{
\backslash
noindent{
\backslash
bf Proof:}
\backslash
hspace*{1em}}{
\backslash
qed
\backslash
bigskip}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{proof-sketch}{
\backslash
noindent{
\backslash
bf Sketch of Proof:}
\backslash
hspace*{1em}}{
\backslash
qed
\backslash
bigskip}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{proof-idea}{
\backslash
noindent{
\backslash
bf Proof Idea:}
\backslash
hspace*{1em}}{
\backslash
qed
\backslash
bigskip}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{proof-of-lemma}[1]{
\backslash
noindent{
\backslash
bf Proof of Lemma #1:}
\backslash
hspace*{1em}}{
\backslash
qed
\backslash
bigskip}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{proof-attempt}{
\backslash
noindent{
\backslash
bf Proof Attempt:}
\backslash
hspace*{1em}}{
\backslash
qed
\backslash
bigskip}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{proofof}[1]{
\backslash
noindent{
\backslash
bf Proof}
\end_layout

\begin_layout Plain Layout

    of #1:
\backslash
hspace*{1em}}{
\backslash
qed
\backslash
bigskip}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newenvironment{remark}{
\backslash
noindent{
\backslash
bf Remark}
\backslash
hspace*{1em}}{
\backslash
bigskip}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%%%%%%%%%% My additions
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\newcommand{\fakebold}[1]{\ThisStyle{\ooalign{$\SavedStyle#1$\cr%
\kern -\bshft$\SavedStyle#1$\cr%
\kern \bshft$\SavedStyle#1$}}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%%Michal%% ==> Change the lecture number, lecture date, and Scribe name
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
finalProjTitle
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

March 17, 2019
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

Dr.
 Adam Morrison
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

Liad Aben Tzur, Sapir Freizeit and Almog Freizeit
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

Transactional Data Structures
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%%Michal%%  Name the first section.
  You can then use more sections (and, if needed, subsections)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Abstract
The idea of transactional data structures is to enable performing complex
 atomic transactions.
 It is widely used in many software and algorithms which use parallelism.
 Usually these kind of data structures are performance oriented and therefore
 a high-performance implementation for it is a novel cause.
 There exists a paper trying to address this point (Transactional Data Structure
 Libraries (TDSL) - http://webee.technion.ac.il/ 
\begin_inset space ~
\end_inset

idish/ftp/TransactionalLibrariesPLDI16.pdf), yet for now only a java implementati
on exists for it (TODO: add link), which is buggy and use GC which affects
 performance.
 Therefore, our main goal in this project was to implement a C++ version
 of it, using memory reclamation.
 By doing so we hoped to achieve better results.
 
\end_layout

\begin_layout Section
Transactional Data Structures - TDS
\end_layout

\begin_layout Standard
A transactional data structure is a data structure with its native operations
 (such as add or remove in a list and enqueue in a queue), plus two special
 operations: 
\shape italic
TXBegin
\shape default
 and 
\shape italic
TXCommit
\shape default
.
 The library guarantees atomicity for each group of operations executed
 in between a TXBegin and a TXCommit (a 
\series bold
transaction
\series default
) – meaning that either they succeed together, or they will all fail (no
 partial results are visible for any other thread).
 
\begin_inset Newline newline
\end_inset

 Our implementation for the library is highly based on the paper [1] (TODO
 – add link).
 In this paper, the method offered for implementation is to make each thread
 have its own read-set and write-set which it updates inside a transaction.
 At the end of the transaction, the thread acquires locks of all the elements
 in its read/write sets and make sure it is safe to update all of them.
 “Safe” is defined via a 
\shape italic
global version clock (GVC)
\shape default
, where node is safe to be changed if the GVC observed at the insertion
 of this node to the write/read sets is equal to the GVC observed after
 acquiring its lock.
 Only if all the nodes in the set are safe to be changed, the transaction
 succeeded.
 Otherwise, the transaction fails.
\begin_inset Newline newline
\end_inset

 In order to minimize the contention between different threads, the library
 maintains an Index.
 The index is basically a concurrent skip-list, which is always updated
 only by a successful transaction.
 When finding a node in the list, one should go and search for it in the
 index.
 The index guarantee is to return a node which key is less than yours, and
 all the requested thread remains to do is to walk from this node forward,
 which spreads the threads along the list and minimizes collisions.
\end_layout

\begin_layout Section
The Java Implementation
\end_layout

\begin_layout Section
Our C++ Implementation
\end_layout

\begin_layout Standard
A Github repostitory is available here - https://github.com/liadab/TransactionalD
ataStructures (TODO - link)
\end_layout

\begin_layout Subsection
Changes
\end_layout

\begin_layout Standard
When implementing the library in C++ we made some changes to the original
 implementation in Java which we based on:
\end_layout

\begin_layout Subsubsection
Index
\end_layout

\begin_layout Standard
The index is highly lean on the Java implementation yet have some changes.
 In order to fully understand the changes, lets discuss shortly about the
 index’s design.
 
\begin_inset Newline newline
\end_inset

 As mentioned before, the index is basically a skip list.
 Therefore, it has several different levels, each level starts with a special
 node which is the head of the that level’s list.
 Each index node has a pointer to the next node in its layer, and a pointer
 downwards to the appropriate node on level lower (at the bottom layer this
 pointer is NULL).
 Each index node points also to the real Linked List Node, where nodes in
 different levels corresponding to the same LL-node.
 
\begin_inset Newline newline
\end_inset

 When a new node is added to the index, after its level is chosen randomly,
 all of its index nodes at different levels of the skip list is created,
 pointed to each other in the “down” pointer.
 Therefore, for correctness, one should always insert the new nodes from
 bottom level upwards, so that nodes in the index will always point to another
 node which is in the index as well.
 Yet for some reason the Java implementation made all the nodes in the index,
 including the head nodes, point only downwards, so the insertion is performed
 from top level downwards as well.
 This is our first change: we made only the heads a double-linked-list,
 meaning that each head has both a pointer downwards and upwards to the
 lower and higher levels respectively.
 Doing so made insertion from bottom up more elegant yet added some subtle
 pointes we had to treat carefully.
 
\begin_inset Newline newline
\end_inset

 Another addition to our index is a function called 
\shape italic
“findInsertionPoints”
\shape default
, which given a node returns all the insertion points for it in all the
 different levels (aka two vectors corresponding to the previous and next
 node in each level).
 In that way the contention between different threads is minimized at insertion
 as well, other than only at searching.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Subsubsection
Templates
\end_layout

\begin_layout Standard
Each of our node is a template class, which is templated upon both its key
 and its value.
 This method enables flexibility when using our library yet remains the
 implementation neat and elegant.
 
\begin_inset Newline newline
\end_inset

 The only demand from the keys is to act like numbers, in the manner that
 they have to support the “+”, “-“ operations and the std::numericlimit
 function.
\end_layout

\begin_layout Subsubsection
LNodeWrapper
\end_layout

\begin_layout Standard
One of our main goals at the project was to implement the library in C++
 without neglecting memory reclamation in order to support large data sets.
 We wanted to compare different methods of memory reclamation, as well as
 a leaking algorithm.
 Therefore, we came up with the 
\shape italic
LNodeWrapper
\shape default
 design.
 The wrapper enables memory management to be hidden from the user and to
 be managed fully by the wrapper.
 
\begin_inset Newline newline
\end_inset

 In that way we could easily test and compare different memory reclamation
 models, with as minimum changes as possible, and in a short amount of time.
\end_layout

\begin_layout Subsubsection
Multiple Executables
\end_layout

\begin_layout Standard
In order to compare the different memory reclamation approaches, we created
 many different executables, one for each method.
 The comparison was made by a different python script which only had to
 run the different executables and measure the results.
 
\begin_inset Newline newline
\end_inset

 Therefore it is easy for a user to choose which model he prefer to use
 when using our library, depends if he cares more about efficiency or perhaps
 he prefer to not approve any memory leak, as small as it may be.
\end_layout

\begin_layout Subsection
Non-Leaking Algorithm
\end_layout

\begin_layout Subsubsection
Using Shared Pointers
\end_layout

\begin_layout Subsubsection
Using DEBRA
\end_layout

\begin_layout Standard
TODO: write about it.
 
\begin_inset Newline newline
\end_inset

 When integrating the DEBRA library in our project we encountered a problem.
 In the current Index’s design, deleting a node is not a linearizable operation.
 
\begin_inset Newline newline
\end_inset

 In details, because each conceptual node may be referred by several different
 index's nodes (at different layers), the design is that each thread encountered
 a deleted node (one of which its value is set to NULL), unlinks it from
 the list at the current level it was at.
 This method of deletion is doing a great job in improving performance,
 yet it makes it impossible to cooperate with DEBRA.
 The reason is that DEBRA has to know when is it safe to remove the node,
 aka when it is not accessible by any thread.
 Due to the fact that many different threads can erase the - TODO: fix it
\end_layout

\begin_layout Section
Testing System
\end_layout

\begin_layout Standard
Write about GTest and thread runner
\end_layout

\begin_layout Section
Testing Environment
\end_layout

\begin_layout Subsection
Our Running Senario
\end_layout

\begin_layout Standard
We wrote a similar running senario for both the Java implementation mentioned
 in [1], and our C++ implementations:
\end_layout

\begin_layout Enumerate
First, we receive the parameters: amount of threads, amount of total tasks,
 amount of tasks per transaction, total percent of insert operations, and
 total percent of remove operations (the rest will be search opeartions).
\end_layout

\begin_layout Enumerate
We create a pool of random tasks, so the randomization process is not included
 in our time measurement.
\end_layout

\begin_layout Enumerate
We create a linked list (we use the linked list as our study case) and initializ
e it with nodes.
 By doing that, we start the actual measurement from a 'clean' environment.
\end_layout

\begin_layout Enumerate
We create a bunch of workers in separate threads as the amount of threads
 we got.
 Each worker receives a different section of the tasks pool from step (2),
 and a pointer to the linked list we created in (3), and we let the workers
 run parallel and perform the tasks from the pool.
\end_layout

\begin_layout Enumerate
In the last stage we print our results.
\end_layout

\begin_layout Subsubsection
notes
\end_layout

\begin_layout Enumerate
We measure the running time only of step 4 - where the parallel work is
 done on the data structure.
\end_layout

\begin_layout Enumerate
We use the JAVA implementation from the articel as-is, the only thing we
 added is the Main file, that executes the senario described above.
\end_layout

\begin_layout Subsection
Running and Output Examples
\end_layout

\begin_layout Subsubsection
Running Examples
\begin_inset Formula 
\begin{align*}
our\ non-leaking\ CPP & ./tds\ 2\ 1000\ 10\ 40\ 50\\
our\ leaking\ CPP & ./tds\_unsafe\ 2\ 1000\ 10\ 40\ 50\\
our\ using-debra\ CPP & ./tds\_debra\ 2\ 1000\ 10\ 40\ 50\\
JAVA\ implementation\ from\ the\ paper & ./run\ 2\ 1000\ 10\ 40\ 50
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Here 2 is the number of threads that will run in parallel, 1000 is the total
 number of tasks (each thread will execute 500 tasks), 10 is the amount
 of tasks per transaction, 40 is the percent of inserts tasks, and 50 is
 the percent of remove tasks.
\begin_inset Newline newline
\end_inset

Overall we programmed 3 executables: tds, tds_debra and tds_unsafe.
\end_layout

\begin_layout Subsubsection
Output Example:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted1.png

\end_inset


\end_layout

\begin_layout Subsubsection
Output explenation
\end_layout

\begin_layout Standard
At the beginning we print the initial size of the linked list.
 After the workers are done, for each thread we count the amount of inserts
 and removes occured, meaning inserts and removes that changed the data
 structure state.
 Also, we count the number of succesful operations and the number of failure
 opearations, where here a 'failure' means that the transaction aborted
 due to a change in the data structure.
 At the end, we print a summary of the details.
 The output is equal for all the implementation vesrions.
\end_layout

\begin_layout Subsection
Running all together - the Python script
\end_layout

\begin_layout Standard
To easily run all 4 implementations and compare them, we wrote a python
 script named final_proj_exp.py (it runs with python version 3.4).
 The script gets as an input all the parameters displayed in 5.1.1, and also
 the parameters 
\begin_inset Formula $max\ threads$
\end_inset

 and 
\begin_inset Formula $amount\ runs$
\end_inset

.
 
\begin_inset Formula $\forall1\le i\le max\ threads:$
\end_inset

 the script runs each implementation with 
\begin_inset Formula $i$
\end_inset

 threads for 
\begin_inset Formula $amount\ runs$
\end_inset

 times, and caclulates the avarage parameters among the 
\begin_inset Formula $amount\ runs$
\end_inset

 runs.
 In the end, the script creates a plot presenting the differences among
 the implementations (the plot is saved under the folder 
\begin_inset Quotes eld
\end_inset

out
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Subsection
Technical details
\end_layout

\begin_layout Enumerate
All the JAVA code can be found under 
\begin_inset Quotes eld
\end_inset

banchmark/src
\begin_inset Quotes erd
\end_inset

 in our git repository.
 An explenation of how to run the program can be found in banchmark/README_COMPI
LATION.txt.
\end_layout

\begin_layout Enumerate
The Python script can also be found under 
\begin_inset Quotes eld
\end_inset

banchmark
\begin_inset Quotes erd
\end_inset

 directory.
 Note: it is important to run the script from within the directory (so JAVA
 will be able to access its jarfile).
 The script arguments can be seen here:
\begin_inset Newline newline
\end_inset

 
\begin_inset Graphics
	filename python args.png

\end_inset


\end_layout

\begin_layout Enumerate
All the CPP exectuables (tds, tds_unsafe, tds_debra) can be found under
 
\begin_inset Quotes eld
\end_inset

build
\begin_inset Quotes erd
\end_inset

.
 To compile the CPP program: from within 
\begin_inset Quotes eld
\end_inset

build/
\begin_inset Quotes erd
\end_inset

 run 
\begin_inset Quotes eld
\end_inset

cmake..
\begin_inset Quotes erd
\end_inset

, and then: 
\begin_inset Quotes eld
\end_inset

make -j
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsection
Code issues:
\end_layout

\begin_layout Enumerate
When we ran the JAVA implementation from [1], we saw that sometimes the
 expected size of the linked list at the end of the running doesn't fit
 the actual size of the list.
 The expected size is calculated during the runtime, by following the amount
 of inserts and removes operations that occurred, while the actual linked
 list size is calculate asynchronously by iterating the linked list with
 a counter in the end of the running.
 In this project we used the JAVA code as a black box, but maybe it follows
 from unsolved edge cases in the index implementation we observed.
\end_layout

\begin_layout Enumerate
Sometimes our CPP implementation crushes due to allocating issues.
 After trying to understand the problem, we found that, despite the assumption
 we based on when we wrote the code, CPP shared_ptr's are not thread safe
 in some edged cases (as described in https://stackoverflow.com/questions/4217298
8/c11-shared-pointer-thread-safety-is-broken).
 But, this bug happens rarely, and after running a bunch of tests we didn't
 find uncorrectness issues in our code.
\end_layout

\begin_layout Section
Results and Conclusions
\end_layout

\begin_layout Subsection
The Results
\end_layout

\begin_layout Standard
The results here present a running example of 10000 tasks, 10 tasks per
 transaction, and each measure was taken as the average case of 10 samples.
 Again, operations are considered as succeed if they were not aborted by
 the transaction mechanism (it is a normal behaviour).
\end_layout

\begin_layout Subparagraph
mixed case (50-50 percent of inserts and removes)
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename 50_50_times.png
	scale 50

\end_inset


\begin_inset Graphics
	filename 50_50_succ_ops.png
	scale 50

\end_inset


\end_layout

\begin_layout Subparagraph
inserts case (all tasks are inserts)
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename 100_inserts_times.png
	scale 50

\end_inset

 
\begin_inset Graphics
	filename 100_inserts_succ_ops.png
	scale 50

\end_inset


\end_layout

\begin_layout Subsection
Conclusions
\end_layout

\begin_layout Enumerate
We can see that there is not a big difference between the mixed case and
 the inserts case.
 This behaviour makes sense, because there is not a big difference between
 the two operations in the aspect of the algorithm.
\end_layout

\begin_layout Enumerate
We see that when we run with more threads, more operations fail due to transacti
on abort, as we would expect.
\end_layout

\begin_layout Enumerate
We can see that in terms of perofrmence, the CPP implementation is doing
 better then the JAVA implementation, when running with more then ~10 threads.
 It is important to mention that we suspected that maybe for some reason
 the JAVA implementation from [1] is not running in parallel.
 To check this option, we added print commands inside the workers code and
 made sure the messages were printed alternately.
 For that reason we believe the JAVA implementation does run in prarllel.
 Understanding the dieffrences between the implementations might be tricky,
 because there are many aspects of differences between JAVA and CPP.
 But, since we see that our CPP implementation runs faster then the JAVA
 implementation from [1] only after using a few threads, and regardless
 to the caring of memory leak in the CPP code, we assume this gap is more
 attached with the general differences between JAVA and CPP and is not necessari
ly directly related to the memory cleaning.
\end_layout

\begin_layout Enumerate
It seems that there are not dramatic differences between the CPP implementations.
 Yet, the experiments above shows that in general, running in unsafe mode
 is faster then running in the non leaking mode, probably due to the clear
 overhead of ensuring the safetiness of the second.
 Whats is maybe more surprising, is that using debra is a bit slower then
 using the safe mode.
 Maybe this fact is related to general overhead of Debra implementation
 as it uses more complicated methods.
\end_layout

\begin_layout Section
Future Work
\end_layout

\begin_layout Enumerate
Add template wrapper for all of our structs (INdexNode, Qnode,…) 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bibfile"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
